---
title: "STAT 231: Problem Set 6B"
author: "Willie Cohen"
date: "due by 10 PM on Friday, April 2"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

This homework assignment is designed to help you further ingest, practice, and expand upon the material covered in class over the past week(s).  You are encouraged to work with other students, but all code and text must be written by you, and you must indicate below who you discussed the assignment with (if anyone).  

Steps to proceed:

\begin{enumerate}
\item In RStudio, go to File > Open Project, navigate to the folder with the course-content repo, select the course-content project (course-content.Rproj), and click "Open" 
\item Pull the course-content repo (e.g. using the blue-ish down arrow in the Git tab in upper right window)
\item Copy ps6B.Rmd from the course repo to your repo (see page 6 of the GitHub Classroom Guide for Stat231 if needed)
\item Close the course-content repo project in RStudio
\item Open YOUR repo project in RStudio
\item In the ps6B.Rmd file in YOUR repo, replace "YOUR NAME HERE" with your name
\item Add in your responses, committing and pushing to YOUR repo in appropriate places along the way
\item Run "Knit PDF" 
\item Upload the pdf to Gradescope.  Don't forget to select which of your pages are associated with each problem.  \textit{You will not get credit for work on unassigned pages (e.g., if you only selected the first page but your solution spans two pages, you would lose points for any part on the second page that the grader can't see).} 
\end{enumerate}

```{r, setup, include=FALSE}
library(tidyverse)
library(tidytext)
library(wordcloud)
library(textdata)

knitr::opts_chunk$set(
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
```


\newpage 
# If you discussed this assignment with any of your peers, please list who here:

> ANSWER: Amaya Smole

\newpage
# Trump Tweets

David Robinson, Chief Data Scientist at DataCamp, wrote a blog post ["Text analysis of Trump's tweets confirms he writes only the (angrier) Android half"](http://varianceexplained.org/r/trump-tweets/).

He provides a dataset with over 1,500 tweets from the account realDonaldTrump between 12/14/2015 and 8/8/2016.  We'll use this dataset to explore the tweeting behavior of realDonaldTrump during this time period.

First, read in the file. Note that there is a `TwitteR` package which provides an interface to the Twitter web API.  We'll use this R dataset David created using that package so that you don't have to set up Twitter authentication.  

```{r}
load(url("http://varianceexplained.org/files/trump_tweets_df.rda"))
```

## A little wrangling to warm-up

1a.  There are a number of variables in the dataset we won't need.  

- First, confirm that all the observations in the dataset are from the screen-name `realDonaldTrump`.  

- Then, create a new dataset called `tweets` that only includes the following variables:

- `text`
- `created`
- `statusSource`

```{r}
#count total tweets
count(trump_tweets_df)

#test to see if number of tweets by the screename is equivalent
trump_tweets_df %>%
  count(screenName)

#create new df
tweets <- trump_tweets_df %>%
  select(text, created, statusSource)



```

\newpage
1b. Using the `statusSource` variable, compute the number of tweets from each source.  How many different sources are there?  How often are each used?

> ANSWER:  There are 5 total sources, an instagram source and 4 twitter sources. Both the instagram source and the twitter for iPad source are only used one time, with the other three being used more frequently. The vast majority of the tweets come from the twitter for Android and twitter for iPhone sources, with just over half of the total able to be attributed to the android source and about forty percent to the iphone source. The twitter web client source was also used multiple times, but about 5 times less than the iphone and 6 times less than the android. This source only accounts for between five and ten percent of the total tweets sent. 

```{r}
tweets %>%
  count(statusSource)

```

\newpage
1c. We're going to compare the language used between the Android and iPhone sources, so only want to keep tweets coming from those sources.  Explain what the `extract` function (from the `tidyverse` package) is doing below.  Include in your own words what each argument is doing.  (Note that "regex" stands for "regular expression".)

> ANSWER: The status source variable is currently a long and somewhat complicated character column, but we only really care about a piece of the longer characters of each row. So, we can use the extract function to create a second character column from our existing one, only with the information we care about from the first column. Within the extract function, we specify the column we wish to extract from along with the name of the new column we will be creating. Then, we denote our 'regular expression' (regex) which specifies the character string in each line we will be extracting our new column from. In our expression since we write 'regex = "Twitter for (.*)<"' this means that we will taking the strign following "Twitter for" and before "<" for the values of our new column, called source. Since all statusSource character strings do not have such a format as specified in the regex, we remove those rows with our 'remove = FALSE' line, since we only want to analyze iPhone and Android tweets. Then, since we only care about iPhone and Android as specified, we filter for those two values within our new column after the expression. 


```{r}
tweets2 <- tweets %>%
  extract(col = statusSource, into = "source"
          , regex = "Twitter for (.*)<"
          , remove = FALSE) %>%
  filter(source %in% c("Android", "iPhone"))
```


\newpage
## How does the language of the tweets differ by source?  

2a. Create a word cloud for the top 50 words used in tweets sent from the Android.  Create a second word cloud for the top 50 words used in tweets sent from the iPhone.  How do these word clouds compare?  (Are there some common words frequently used from both sources? Are the most common words different between the sources?)

*Don't forget to remove stop words before creating the word cloud.  Also remove the terms "https" and "t.co".*

> ANSWER: The words clouds share some similarities in the most common words. For example, words like "Hillary", "Trump", and "America" can be seen in both word clouds. However, there are some differences in the sizes of these common words and thus their relative frequency in both the sources. Further, the iPhone word cloud has "makeamericagreatagain" as one of its most common words, whereas it is not visible at all in the Android word cloud. Also, the Android word cloud contains more frequent use of names like "Hillary", and "Cruz" as well as words like "Lyin" and "Crooked" which Trump used as nicknames for those people. In general, the Android word cloud has more names, which implies that Trump may have addressed his opponents more aggresively from that source, whereas in the iPhone word cloud we see more locations and campaign slogans which implies these tweets may have been more often self-promoting instead of addressed at others. 

```{r, fig.width=8, fig.height=8}
data(stop_words)

tweetWords <- tweets2 %>%
  unnest_tokens(output = word, input = text
                , token = "ngrams", n = 1) %>%
  anti_join(stop_words, by = "word") %>%
  filter(word != "https", word != "t.co")

word_frequencies <- tweetWords %>%
  group_by(word, source) %>%
  summarize(frequency = n())


word_frequencies %>%
  filter(source == "iPhone") %>%
  with(wordcloud(words = word, freq = frequency, max.words=50))

word_frequencies %>%
  filter(source == "Android") %>%
  with(wordcloud(words = word, freq = frequency, max.words=50))


```

\newpage
2b. Create a visualization that compares the top 10 *bigrams* appearing in tweets by each source (that is, facet by source).  After creating a dataset with one row per bigram, you should remove any rows that contain a stop word within the bigram.  

How do the top used bigrams compare between the two sources?

> ANSWER:  The top used bigrams have some overlap between the two sources, but it appears that the top used Android bigrams include more names (Hillary Clinton, Bernie Sanders, Ted Cruz), including the insulting nicknames Trump used to disparage them (Crooked Hillary, Lyin Ted). While the iPhone tweets share some of the same top 10 bigrams, like "Crooked Hillary" and "Hillary Clinton" the occur with relatively less frequently and rank lower among the top ten most frequent for that source. More of the iPhone tweets seem to be directly referencing the campaign ("makeamericagreatagain 2016", "america trump2016", etc.) and not the people as directly. This could indicate that the Android source was used more often for tweets including such personal attacks compared to the iPhone which was used more often for standard campaign tweets. 

```{r}

tweetBigrams <- tweets2 %>%
  unnest_tokens(output = word, input = text
                , token = "ngrams", n = 2) %>%
  mutate(word2 = word) %>%
  separate(word2, c("first", "second"), sep = " ") %>%
  anti_join(stop_words, by = c("first" = "word")) %>%
  anti_join(stop_words, by = c("second"= "word")) %>%
  filter(first != "https", first != "t.co", second != "https", second != "t.co")

android <- tweetBigrams %>%
  filter(source == "Android") %>%
  count(source, word, sort = TRUE) %>%
  slice(1:10)
  
iphone <- tweetBigrams %>%
  filter(source == "iPhone") %>%
  count(source, word, sort = TRUE) %>%
  slice(1:10)

joined <- android %>%
  bind_rows(iphone)

joined %>%
  ggplot(aes(x = reorder(word,n), y = n, color = word, fill=word)) +
  geom_col(show.legend = FALSE) +
  xlab(NULL) +
  coord_flip() +
  facet_wrap(~source, scales = "free_y") +
  labs(x= "Frequency", y = "Bigram") +
  ggtitle("Frequency of Bigrams Used, Faceted by Source")



```


\newpage
2c. Consider the sentiment.  Compute the proportion of words among the tweets within each source classified as "angry" and the proportion of words classified as "joy"  based on the NRC lexicon.  How does the proportion of "angry" and "joy" words compare between the two sources?  What about "positive" and "negative" words?  

> ANSWER: The ratio of words classified with the sentiment "anger" in the NRC lexicon to those classified with "joy" is 1.36 (363/267) for the Android and for iPhone it is 1.08 (170/163). This implies that the words used in Trump's tweets from the Android were relatively more angry than those sent from the iPhone, as the words are classified by the NRC lexicon. We see a similar relationship when looking at words classified as "positive" and "negative", as the ratio for such words for the Android is 0.88 (647/734)  and 0.63 (262/419) for the iPhone. Given both of these results, Trump seems to be negative more frequently in the tweets from the Android, but still makes tweets with negative or angry words from both sources.  


```{r}
nrc_lexicon <- get_sentiments("nrc")

tweetSentiments <- word_frequencies %>%
  inner_join(nrc_lexicon, by = "word") %>%
  filter(sentiment == "anger" | sentiment == "joy") %>%
  group_by(sentiment, source) %>%
  summarize(totalfreq = sum(frequency), source = source) %>%
  unique()

head(tweetSentiments)

proportionAnroid <- 363/267
proportionIphone <- 170/163

proportionAnroid
proportionIphone
  

tweetSentiments2 <- word_frequencies %>%
  inner_join(nrc_lexicon, by = "word") %>%
  filter(sentiment == "positive" | sentiment == "negative") %>%
  group_by(sentiment, source) %>%
  summarize(totalfreq = sum(frequency), source = source) %>%
  unique()

head(tweetSentiments2)

proportionAnroid2 <- 647/734
proportionIphone2 <- 262/419

proportionAnroid2
proportionIphone2


```


\newpage
2d. Lastly, based on your responses above, do you think there is evidence to support Robinson's claim that Trump only writes the (angrier) Android half of the tweets from realDonaldTrump?  In 2-4 sentences, please explain.

> ANSWER: Based on the data and responses above, I do believe it is fair to say that Trump may have been negative more often in his Android tweets, but this does not mean that the tweets from the iPhone were exlcusively positive. In part (c), we see that the proportion of negative words used to positive words used are 0.88 for the Android and 0.63 for the iPhone. Though this indicates negative words were used more frequently on the Android, it still remains that a significant portion of the words in the iPhone tweets were also negative. Further, in the analysis of the bigrams we saw the top Android bigrams more centered around people, with "Crooked Hillary" being the number one occuring bigram. This does indicate that Trump may have sent more angry and personal attacks from the Android, however, "Crooked Hillary" was also among the most popular bigrams sent from the iPhone, which would indicate he sent such attacks from both sources. So overall, I would agree partially with Robinson's claim that Trump's tweets from the Android were angrier, but his tweets from the iPhone were also angry, just less so.

