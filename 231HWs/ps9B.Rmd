---
title: "STAT 231: Problem Set 9B"
author: "YOUR NAME HERE"
date: "due by 10 PM on Friday, May 14"
output:
  pdf_document: default
---

This homework assignment is designed to help you further ingest, practice, and expand upon the material covered in class over the past week(s).  You are encouraged to work with other students, but all code and text must be written by you, and you must indicate below who you discussed the assignment with (if anyone).  

Steps to proceed:

\begin{enumerate}
\item In RStudio, go to File > Open Project, navigate to the folder with the course-content repo, select the course-content project (course-content.Rproj), and click "Open" 
\item Pull the course-content repo (e.g. using the blue-ish down arrow in the Git tab in upper right window)
\item Copy ps9B.Rmd from the course repo to your repo (see page 6 of the GitHub Classroom Guide for Stat231 if needed)
\item Close the course-content repo project in RStudio
\item Open YOUR repo project in RStudio
\item In the ps9B.Rmd file in YOUR repo, replace "YOUR NAME HERE" with your name
\item Add in your responses, committing and pushing to YOUR repo in appropriate places along the way
\item Run "Knit PDF" 
\item Upload the pdf to Gradescope.  Don't forget to select which of your pages are associated with each problem.  \textit{You will not get credit for work on unassigned pages (e.g., if you only selected the first page but your solution spans two pages, you would lose points for any part on the second page that the grader can't see).} 
\end{enumerate}

```{r, setup, include=FALSE}
knitr::opts_chunk$set(
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
```


\newpage 
# If you discussed this assignment with any of your peers, please list who here:

> ANSWER:

\newpage
# 1. Ethics follow-up

(a) Thinking about the discussion you had with the first group you were with during class on Tuesday 5/4 (focused on either "Predicting Policing & Recidivism" or "Predicting Financial Risk"), did your perspective on, or understanding of, any of the questions shift?  If so, please describe.  If not, was there anything you found surprising in the resources or your first group discussion?

> ANSWER: Entering our group discussion regarding predictive policing algorithms, I was pretty firm in my belief that they should not be employed given the inherent bias of the data that is used to create them. Bias data breeds an algorithm that carries this same bias which is something that was touched upon during the Ted Talk. However, I think during the conversation my group helped me understand how the employment of such algorithms is not only unhelpful, but actively harming the communities that the algorithm is biased against. There is a prevailing notion that computers carry no bias and exist separate and apart from the biases that all humans hold. Then, if police officers are to believe that these computers carry no bias, they have no incentive to analyze their practices and understand how they may be hurting the communities they claim they want to protect. Algorithms help these police departments deflect responsibility and accountability for their biases by blaming them on a machine. 

(b) Thinking about the discussion you had with the second group you were with during class on Tuesday 5/4 (focused on considering the use of algorithms in the college admissions process), did your perspective on, or understanding of, the use of algorithms in these contexts shift?  If not, was there anything you found surprising in the resources or your second group discussion?

> ANSWER: In our second group discussion, most of us were in agreement that algorithms could be used in certain contexts within the college admissions process. Most of the group agreed that for some large state schools that receive tens of thousands of applications, it would be nonsensical to sort through every one looking for things such as test scores or grades/GPA. So, employment of algorithms to help eliminate some of the pool and cut down the field somewhat, so long as they were only analyzing numerical figures seemed pretty fair. However, we acknowledged that this process would not be perfect as it's possible the algorithm could not contextualize test scores and grades because, for example, we know that standardized test scores are directly correlated with socioeconomic status, which is something I had not thought about previously. We were all in agreement that algorithms should not be used to evaluate essays of any form the personal statements are often emotional pieces with artistic merit, so in having a machine judge them they may lose much of their power. This is especially true since, as someone noted in our group, good writers may break from common grammatical syntax for dramatic or artistic effect, which is something a computer may not understand. 


\newpage

**CHOOSE ONE OF 2 (Clustering), 3 (Simulations) or 4 (SQL) to COMPLETE**

# 2. Clustering
## MDSR Exercise 9.5

Baseball players are voted into the Hall of Fame by the members of the Baseball Writers of America Association.  Quantitative criteria are used by the voters, but they are also allowed wide discretion.  The following code identifies the position players who have been elected to the Hall of Fame and tabulates a few basic statistics, include their number of career hits (`tH`), home runs (`tHR`), runs batted in (`tRBI`), and stolen bases (`tSB`).  Use the `kmeans()` function to perform a cluster analysis on these players.  Describe the properties that seem common to each cluster.

*Don't forget to standardize the variables before clustering, if applicable.*

> ANSWER: Since the scales of these variables varied widely, they first needed to be standardized. Also after conducting an plotting within cluster variation against number of clusters, there wasn't a clear elbow; however, the plot seemed to flatten out around clusters 4,5, and 6, so I decided to do our clustering analysis in five different clusters. In terms of commonalities between clusters, cluster 5 seemed to characterize with high amounts of hits, homeruns, and RBIs, but very few stolen bases. On the other hand, cluster 3 contains 5 players, each of which are in the top 6 of both understandardized and standardized stolen bases. The players in cluster 3 also tended to have a large number of hits, but relatively fewer homeruns and a large range of RBIs. Cluster 4 appears to contain the least prolific performers across the board in our four counting stats, containing players on the bottom end of each of them. Clusters 2 and 3 are more middling but differ slightly in the power and speed stats of homeruns and stolen bases. Cluster 3 containing players with few stolen bases, but above average (at least for our data set) homerun and RBI values, while cluster 2 is more in the middle of the road in terms of homers and RBIs, but containing players on the upper end of the hits scale and the higher end of the base stealing scale outside cluster 3. 


```{r, message = FALSE}
library(tidyverse)
library(mdsr)
library(Lahman)
library(GGally)

##### PLEASE DO NOT CHANGE THIS SEED NUMBER
##### keep set.seed(75) 
set.seed(75)

#standardized the counting stats
hof <- Batting %>%
  group_by(playerID) %>%
  inner_join(HallOfFame, by = "playerID") %>%
  filter(inducted == "Y" & votedBy == "BBWAA") %>%
  summarize(tH = sum(H), tHR = sum(HR), tRBI = sum(RBI), tSB = sum(SB)) %>%
  filter(tH > 1000) %>%
  mutate_if(is.numeric, funs(`std`=scale(.) %>% as.vector()))

vars_std <- c("tH_std", "tHR_std", "tRBI_std"
              , "tSB_std")

#to see how many clusters
fig <- matrix(NA, nrow=10, ncol=2)

for (i in 1:10){
  fig[i,1] <- i
  fig[i,2] <- kmeans(hof[,vars_std]
                        , centers=i
                        , nstart=20)$tot.withinss
}

#within cluster variation plot
ggplot(data = as.data.frame(fig[2:10,]), aes(x = V1, y = V2)) +
  geom_point() + 
  geom_line() +
  scale_x_continuous(breaks=c(1:10)) +
  labs(x = "K", y = expression("Total W"[k]))

#k-means output
km5 <- kmeans(hof[,vars_std]
                        , centers=5
                        , nstart=20)

#add clusters to our data set
hof <- hof %>%
  mutate(clusters = as.character(km5$cluster))

#ggally analysis
ggpairs(data = hof, aes(color = clusters), columns = vars_std)

```


\newpage

**CHOOSE ONE OF 2 (Clustering), 3 (Simulations) or 4 (SQL) to COMPLETE**

# 3. Simulation
## MDSR Exercise 10.6 (modified) 

\textit{Equal variance assumption}:  What is the impact of the violation of the equal variance assumption for linear regression models?  Repeatedly generate data from two "true" models:

(1) where the equal variance assumption is met: $y_i$ ~ $N(\mu_i, \sigma)$
(2) where the equal variance assumption is violated: $y_i$ ~ $N(\mu_i, \sigma_i)$

, where $\mu_i = -1 + 0.5*X_{1i} + 1.5*X_{2i}$, $\sigma$=1 in (1), $\sigma_i=1+X_{2i}$ in (2), and $X_1$ is a binary predicator and $X_2$ is Uniform(0,5).

Code to get you started is given below.  (Note that in (2) the standard deviation is dependent upon x2, which is random; i.e., the equal variance assumption is violated.  The Ys are *not* generated from a distribution with the same variance in (2).)

For each simulation, fit the linear regression model and display the distribution of 1,000 estimates of the $\beta_1$ parameter.  Does the distribution of the parameter follow a normal distribution in both cases?  Is it centered around $\beta_1$?  How does the variability in the distributions compare (variance in $\hat{\beta}_1$ when the equal variance assumption is met vs. when it is violated)?

> ANSWER:   

```{r}
library(tidyverse)

# number of observations in each sample
n_obs <- 250

rmse <- 1
x1 <- rep(c(0,1), each=n_obs/2)
x2 <- runif(n_obs, min=0, max=5)
beta0 <- -1
beta1 <- 0.5
beta2 <- 1.5

# for scenario 1, where equal var assumption is met (sd is constant value, rmse)
y1 <- beta0 + beta1*x1 + beta2*x2 + rnorm(n=n_obs, mean=0, sd=rmse)
# for scenario 2, where equal var assumption is violated (sd depends on x2)
y2 <- beta0 + beta1*x1 + beta2*x2 + rnorm(n=n_obs, mean=0, sd=rmse + x2)
  
# for scenario 1
mod1 <- lm(y1 ~ x1 + x2)
# for scenario 2
mod2 <- lm(y2 ~ x1 + x2)

summary(mod1)$coeff["x1","Estimate"]

# repeatedly generate data, fit the model, and extra the beta1 coefficient (1,000 times)
# number of simulations
n_sim <- 1000

# target visualization: sampling distribution of \hat{beta}_1
#                 (histogram or density plot of \beta_1 estimates), by scenario
# target summary numbers: mean and sd/variance of beta_1 estimates, by scenario

# loop through iterations

# create target visualization

# create target summaries
```


\newpage

**CHOOSE ONE OF 2 (Clustering), 3 (Simulations) or 4 (SQL) to COMPLETE**

# 4. SQL
## Airline flights

4a. Identify what years of data are available in the `flights` table of the airlines database using SQL code.

> ANSWER: 

```{r,eval=TRUE}
library(RMySQL)
library(mdsr)
# dbConnect_scidb is accesible from the mdsr package
aircon <- dbConnect_scidb("airlines")

# can use SHOW and EXPLAIN commands to explore what tables are available
# through this connection, and what variables/fields are in each table
dbGetQuery(aircon, "SHOW TABLES")
dbGetQuery(aircon, "EXPLAIN airports")
# can view first few obs of a table to see what the fields look like 
dbGetQuery(aircon, "SELECT * 
                   FROM airports
                   LIMIT 0,5")
```

```{sql connection=aircon}

```

4b. How many domestic flights flew into Dallas-Fort Worth (DFW) on May 14, 2010?  Use SQL to compute this number. (You can use R code to check it, if you wish.) 

> ANSWER: 

```{sql connection=aircon}

```

4c.  *Among the flights that flew into Dallas-Fort Worth (DFW) on May 14, 2010*, compute (using SQL) the number of flights and the average arrival delay time for each airline carrier.  Among these flights, how many carriers had an average arrival delay of 60 minutes or longer?

> ANSWER: 

```{sql connection=aircon}

```

